<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge, chrome=1" />
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no' />
    <title>Experimental tfjs crevasse predictor</title>
    <style>
        html,
        body {
            margin: 0;
            padding: 0;
            height: 100%;
            width: 100%;
        }
        #devTestingDemo {
            position: relative;
            top: 0;
            bottom: 0;
            width: 100%;
            height: 90%;
            z-index:1;
        }
        #delete, #export, #fileInputButton {
            position: absolute;
            top:135px;
            right:10px;
            z-index:100;
            background:white;
            color:black;
            padding:6px;
            border-radius:4px;
            font-family: 'Helvetica Neue';
            cursor: pointer;
            font-size:12px;
            text-decoration:none;
        }
        #delete {
            top:165px;
        }
        #export {
            top:195px;
        }
    </style>
    
    <!--Add leaflet-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js"></script>
    
    <!--Add leaflet.draw plugin-->
    <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/leaflet.draw/1.0.2/leaflet.draw.css' />
    <script src='https://cdnjs.cloudflare.com/ajax/libs/leaflet.draw/1.0.2/leaflet.draw.js'></script>
    
    <!--Add tensorflowjs-->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.10.3/dist/tf.min.js" crossorigin=""></script>
    
    <!--Add proj4js-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/proj4js/2.4.4/proj4-src.js"></script>
    

</head>

<body>
<div id="devTestingDemo"></div>
<div id='fileInputButton'>Upload GeoJSON</div>
<input id="fileInput" type="file" style="display:none"/>
<div id='delete'>Delete Features</div>
<a href='#' id='export'>Export GeoJSON</a>
<p>
This is a demo map using Sentinel 1 and 2 data where you can draw crevasse polygons and contribute to Antarctic science!
Digging into the html/javascript will reveal an experimental tensorflowjs model that tries to predict crevasses from raw satellite images.
Note that the model may crash on non-modern devices without WebGL and/or a proper GPU.
Also, this is just a proof of concept with bugs (albeit a cool one)!
</p>
<canvas id="canvas" width=256 height=256></canvas>
<canvas id="canvaspredict" width=256 height=256></canvas>

<script>
async function loadModel() {
  console.log("Loading model");
  const model = await tf.loadModel("tfjs/model.json");
  //const model = await tf.loadModel("https://raw.githubusercontent.com/weiji14/nz_space_challenge/master/tfjs/model.json")
  console.log("Model loaded");
  console.log(model);

  console.log(model.predict(tf.zeros([1, 256, 256, 3])));
  return tf.model({ inputs: model.inputs, outputs: model.outputs });
  //return model;
}

async function init() {
  crevasse_model = await loadModel();
  console.log("Model really loaded!");
  console.log(crevasse_model);
}

init();

// Sentinel Hub WMS service
// tiles generated using EPSG:3857 projection - Leaflet takes care of that
let baseUrl = "https://services.sentinel-hub.com/ogc/wms/5b63030a-a576-4cf4-af58-b2f28ca6b987";
let sentinel2 = L.tileLayer.wms(baseUrl, {
    tileSize: 512,
    attribution: '&copy; <a href="http://www.sentinel-hub.com/" target="_blank">Sentinel Hub</a>',
    maxcc:20,
    minZoom:5,
    maxZoom:16,
    preset:"TRUE_COLOR",
    gain:"0.3",
    gamma:"0.8",
 	layers:"TRUE_COLOR",
 	time:"2018-02-10/2018-02-14",
    format: 'image/png',
});

let sentinel1 = L.tileLayer.wms(baseUrl, {
    tileSize: 512,
    attribution: '&copy; <a href="http://www.sentinel-hub.com/" target="_blank">Sentinel Hub</a>',
    maxcc:20, 
 	minZoom:5, 
 	maxZoom:16, 
 	preset:"SENTINEL-1-EW-RGB-RATIO", 
 	layers:"SENTINEL-1-EW-RGB-RATIO", 
 	time:"2018-02-01/2018-02-28",
    transparent: true,
    format: 'image/png',
}); 

let predictGroup = L.layerGroup()  //we'll put our predicted images into this layer group

let baseMaps = {
    'Sentinel 2 L2C': sentinel2
};

let overlayMaps = {
    'Sentinel 1 EW': sentinel1,
    'Crevasse predictions': predictGroup
}

let map = L.map('devTestingDemo', {
    center: [-78.09574636517269, 168.057861328125], // lat/lng in EPSG:4326
    zoom: 8,
    layers: [sentinel2, predictGroup]
});

var layerController = L.control.layers(baseMaps, overlayMaps, {position: 'topleft'}).addTo(map);

/****
  Leaflet draw stuff, the feature group we'll add features to and drawing controls
  Based on https://bl.ocks.org/danswick/d30c44b081be31aea483
****/
var featureGroup = L.featureGroup().addTo(map);

document.getElementById('fileInput').addEventListener("change", function (evt) {
  var file = evt.target.files[0], // Read first file for this example.
      reader = new FileReader();

  reader.onload = function (e) {
    var fileText = e.target.result;
        fileData = JSON.parse(fileText);
        var loadedGroup = L.geoJson(fileData, {
          onEachFeature: function (feature, layer) {
            featureGroup.addLayer(layer);
          }
        });
    map.fitBounds(loadedGroup.getBounds());
  }
  reader.readAsText(file);
});

var drawControl = new L.Control.Draw({
    position: 'topright',
    draw: {
        circle: false,
        rectangle: false,
        marker: false,
        circlemarker: false,
        polyline: false,
        polygon: {
            allowIntersection: false,
            showArea: true
        }
    },
    edit: {
        featureGroup: featureGroup,
        poly: {
            allowIntersection: false
        }
    }
}).addTo(map);

map.on('draw:created', function(e) {
    // Each time a feaute is created, it's added to the over arching feature group
    featureGroup.addLayer(e.layer);
});

document.getElementById('fileInputButton').onclick = function(e) {
  // on click, popup upload file dialog
  document.getElementById('fileInput').click();
};

document.getElementById('delete').onclick = function(e) {
  // on click, clear all layers
  featureGroup.clearLayers();
};

document.getElementById('export').onclick = function(e) {
    // Extract GeoJson from featureGroup
    var data = featureGroup.toGeoJSON();

    // Stringify the GeoJson
    var convertedData = 'text/json;charset=utf-8,' + encodeURIComponent(JSON.stringify(data));
    
    // Create export
    document.getElementById('export').setAttribute('href', 'data:' + convertedData);
    document.getElementById('export').setAttribute('download','crevasses.geojson');
};


/****
  WMS GetMap stuff, getting an image to pass into tensorflowjs model
****/
var owsUrl = "https://services.sentinel-hub.com/ogc/wms/5b63030a-a576-4cf4-af58-b2f28ca6b987";
var crsWGS84 = new proj4("EPSG:4326");
var crsMapMerc = new proj4("EPSG:3857");

const canvas = document.getElementById("canvas");
const canvaspredict = document.getElementById("canvaspredict");
const ctx = canvas.getContext("2d");
const ctxpredict = canvaspredict.getContext("2d");

map.on("moveend", main);

function main() {
	if (map.getZoom() >= 11) {    //if we are zoomed in close enough to the ground
		get_wms_img();
	} else {
		console.log('Zoom in closer to predict!')
	}
};

async function get_wms_img() {
  var defaultParameters = {
    service: "WMS",
    request: "getMap",
    layers: "TRUE_COLOR",
    styles: "",
    format: "image/jpeg",
    transparent: 'false',
    version: "1.1.1",
    maxcc: 50,
    preset: "TRUE_COLOR",
    gain: "0.3",
    gamma: "0.8",
    time: "2018-02-10/2018-02-14",
    width: 256,
    height: 256,
    srs: 'EPSG:3857',
  };

  var wgsBounds = map.getBounds(); //get width 512 by height 256 bounding Box in WGS84
  var wgsNorthWest = wgsBounds.getNorthWest();
  var wgsSouthEast = wgsBounds.getSouthEast();

  var northwest = proj4(crsWGS84, crsMapMerc, [wgsNorthWest.lng, wgsNorthWest.lat]);
  var southeast = proj4(crsWGS84, crsMapMerc, [wgsSouthEast.lng, wgsSouthEast.lat]);

  var bounds = northwest.concat(southeast);

  var customParams = {
    //bbox: map.getBounds().toBBoxString()
    bbox: bounds
  };

  var parameters = L.Util.extend(defaultParameters, customParams);
  var imgUrl = owsUrl + L.Util.getParamString(parameters); //WMS GetMap url
  console.log(imgUrl);
  
  //https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas
  var img = new Image();
  img.crossOrigin = "Anonymous";
  //img.src = "https://cors-anywhere.herokuapp.com/" + imgUrl; //the WMS GetMap url we are passing in
  img.src = imgUrl;
  
  img.onload = function getImageData() {
    console.log("Image loaded");
    ctx.drawImage(img, 0, 0);
    img.style.display = "none";
    const imageData = ctx.getImageData(0, 0, 256, 256);
		//return imageData;
    imageToTensor(imageData)
  };

  function imageToTensor(img) {
    return tf.tidy(() => {
      console.log("Converting ImageData to tf.tensor");
      const wmsImage = tf.fromPixels(img, 3); // get just the RGB bands from the RGBA data
      const batchedImage = wmsImage.expandDims(0); //convert shape from (256,256,3) to (1,256,256,3)
      const invertedImage = tf.sub(tf.scalar(255, "int32"), batchedImage); //change JS style 0-255 white-black to Python style 0-255 black-white...
      const rescaledImage = invertedImage.toFloat().div(tf.scalar(255)); //convert 0-255 int data to 0-1 float type

      //const y_inter = await tf.toPixels(wmsImage, canvasintermediate);
      predictOnTensor(rescaledImage); //pass the tensor to the predictOnTensor function
    });
  };

  //https://angularfirebase.com/lessons/tensorflow-js-quick-start/
  function predictOnTensor(tensor) {
    return tf.tidy(() => {
      console.log("Starting predict on tensor");
      const prediction = crevasse_model.predict(tensor, { batchSize: 1 });
      //const imageTensor = tf.reshape(prediction, [256, 256]);
      const imageTensor = tf.keep(tf.reshape(prediction, [256, 256]));
      paintImgToCanvas(imageTensor);

      //const reinvertedTensor = tf.keep(tf.sub(tf.scalar(1, "float32"), imageTensor)); //change Python style 0-1 black-white back to JS style 0-1 white-black
      //paintImgToCanvas(reinvertedTensor);
    });
  };

  async function paintImgToCanvas(imgTensor) {
    //return tf.tidy(() => {
    console.log("Painting back to canvas");
    ctxpredict.clearRect(0, 0, 256, 256) //clear the canvas first
    var y_hat = await tf.toPixels(imgTensor, canvaspredict); //paint prediction to canvas!!

    console.log(y_hat);
    
    var dataURL = canvaspredict.toDataURL();
    var predictionOverlay = L.imageOverlay(dataURL, wgsBounds);
    predictGroup.addLayer(predictionOverlay);  //add the prediction map to the predictGroup    
    //});
  };
  
};

</script>
</body>
</html>
